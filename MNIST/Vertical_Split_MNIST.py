# -*- coding: utf-8 -*-
"""VerticalSplit_MNIST.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ub_U5tzwUng8ShH0OWKPFa4ehaflXX1E
"""

# data/load_data.py
import torch
from torchvision import datasets, transforms


def load_mnist_data():
    # Function to transform it in normalized form
    transform = transforms.Compose([
        transforms.ToTensor(),  # Convert to Tensor object
        transforms.Normalize((0.1307,), (0.3081,))
    ])

    # train and test datasets
    train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)
    test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)

    return train_dataset, test_dataset


def vertical_partition_rotating(dataset, num_participants):
    # Firstly an empty list for each participant
    partitions = [[] for _ in range(num_participants)]
    num_rows = dataset[0][0].shape[1]

    # Iterating over each image-label pair in the dataset
    for image, label in dataset:
        # Each image is initialized as a zero tensor with the same shape as the original image, effectively zero-padding all features initially. Only the features corresponding to each participant are filled with actual data, while the rest remain as zeros.
        full_images = [torch.zeros_like(image) for _ in range(num_participants)]

        # We will collect one row for each participant from each image
        for i in range(num_rows):
            participant = i % num_participants
            row_data = image[:, i, :].unsqueeze(1)  # Here we keep the same number of dimensions

            # We have to add the current row to the corresponding full image at the correct position
            full_images[participant][:, i, :] = row_data.squeeze(1)

        # Adding up the completed full images with padding for each participant
        for participant in range(num_participants):
            partitions[participant].append((full_images[participant], label))

    # Combining the rows for each participant into a new dataset
    for i in range(num_participants):
        data_tensors, labels = zip(*partitions[i])
        partitions[i] = torch.utils.data.TensorDataset(
            torch.stack(data_tensors, dim=0),
            torch.tensor(labels)
        )

    return partitions


train_dataset, test_dataset = load_mnist_data()
num_participants = 7  # Example number of participants
train_partitions = vertical_partition_rotating(train_dataset, num_participants)


import matplotlib.pyplot as plt



"""
# We see the first 5 partitioned images from Participant
def show_partitioned_images(partitions, participant_id, num_images=5):
    images, _ = zip(*[partitions[participant_id][i] for i in range(num_images)])
    fig, axs = plt.subplots(1, num_images, figsize=(10, 2))
    for i, img in enumerate(images):
        axs[i].imshow(img.squeeze(), cmap='gray')
        axs[i].axis('off')
    plt.show()

# Show images for the first participant
show_partitioned_images(train_partitions, 1)

"""


# Function to see the how the first image is vertically split in a "robin round" fashion amongst participants
def show_first_image_and_partitions(partitions, num_participants):
    # Then we can reconstruct the complete image from partitions
    num_rows = partitions[0][0][0].shape[1]
    complete_image = torch.zeros_like(partitions[0][0][0])
    for i in range(num_rows):
        participant = i % num_participants
        complete_image[:, i, :] = partitions[participant][0][0][:, i, :]

    # Plotting the complete reconstructed image
    fig, axs = plt.subplots(1, num_participants + 1, figsize=(15, 2))  # +1 for the complete image
    axs[0].imshow(complete_image.squeeze(), cmap='gray')
    axs[0].set_title('CompleteImage')
    axs[0].axis('off')

    # Plotting each partitioned image
    for i in range(num_participants):
        partition_image, _ = partitions[i][0]  # We get the first image from each participant's partition
        axs[i + 1].imshow(partition_image.squeeze(), cmap='gray')
        axs[i + 1].set_title(f'Participant {i+1}')
        axs[i + 1].axis('off')

    plt.show()


# Display the first complete image and its partitions
show_first_image_and_partitions(train_partitions, num_participants)


# For 2 Paticipant Configuration
num_participants = 2  # Example number of participants
train_partitions = vertical_partition_rotating(train_dataset, num_participants)

show_first_image_and_partitions(train_partitions, num_participants)